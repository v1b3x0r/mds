# Layer 4: Communication
> Language, Dialogue, Messages, Semantics

## What & Why
Entities communicate through messages, engage in dialogues, and understand semantic meaning.
Not just collision - **conversation and understanding**.

## Philosophy
"Entities talk, not just react"
Messages are queued (inbox/outbox).
Dialogues are conditional trees (context-aware).
Semantics via embeddings (similarity, clustering).

## Structure
```
4-communication/
â”œâ”€â”€ language/
â”‚   â””â”€â”€ generator.ts        # LLM-powered text generation
â”œâ”€â”€ dialogue/
â”‚   â””â”€â”€ manager.ts          # Dialogue trees, conditions
â”œâ”€â”€ message/
â”‚   â””â”€â”€ queue.ts            # Inbox/outbox message queuing
â”œâ”€â”€ semantics/
â”‚   â”œâ”€â”€ similarity.ts       # Semantic similarity (Jaccard, Levenshtein)
â”‚   â””â”€â”€ embeddings.ts       # OpenAI/Cohere embedding providers
â””â”€â”€ types.ts                # MessageSender, MessageReceiver, DialogueParticipant
```

## Dependencies
âœ… Can import: 0-foundation, 1-ontology, schema, types.ts
âŒ Cannot import: 2-physics, 3-cognition, 5-network, 6-world, 7-interface
ğŸ”„ Used by: 0-foundation/entity (messages), 6-world (dialogue orchestration)

## Key Patterns
**Messages:** `entity.sendMessage(target, { type, content, priority })`
**Dialogue:** `DialogueManager.respond(trigger, context)` â†’ conditional responses
**Semantics:** `findSimilar(text, candidates)` â†’ Jaccard/Levenshtein similarity
**LLM:** `LanguageGenerator.generate(prompt)` â†’ OpenAI/Anthropic/OpenRouter

## Anti-Patterns
âŒ Assume LLM is always available (provide fallbacks)
âŒ Block on message delivery (use async queues)
âŒ Hardcode dialogue responses (use conditional trees)
âŒ Skip semantic caching (embeddings are expensive)

## Common Tasks
**Send message:** `entity.sendMessage(targetId, { type: 'greeting', content: 'à¸ªà¸§à¸±à¸ªà¸”à¸µ' })`
**Setup dialogue:** `entity.addDialogue('intro', [{ lang: { th: 'à¸ªà¸§à¸±à¸ªà¸”à¸µ', en: 'Hello' }}])`
**Check similarity:** `similarity(text1, text2)` â†’ 0..1 score
**Enable LLM:** `enableLLM({ provider: 'openrouter', apiKey })`

## Notes for AI
- Messages use priority queues (high priority first)
- Dialogues support multilingual (lang.th, lang.en)
- Semantics: local methods (Jaccard) or embeddings (OpenAI)
- LLM is optional - system works with local methods
- types.ts breaks circular dependencies (lightweight interfaces)
